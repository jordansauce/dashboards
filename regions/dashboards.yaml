pretrained_sae_paths: null # Paths of the pretrained SAEs to load. Should be a path to a .pt file, or a list of them. Can also be provided as a second argument in the command line.
sae_config_path: null # Path to the config file used to train the SAEs (if null, we'll assume it's at pretrained_sae_paths[0].parent / "config.yaml")
n_samples: 3000
batch_size: 16
minibatch_size_features: 100 # Num features in each batch of calculations. Lower to avoid OOM errors
data: # DatasetConfig for the data which will be used to generate the dashboards
  dataset_name: 'apollo-research/Skylion007-openwebtext-tokenizer-gpt2'
  is_tokenized: True
  tokenizer_name: 'gpt2'
  split: "train"
  n_ctx: 1024
save_dir: null # The directory for saving the HTML feature dashboard files
save_json_data: false
sae_positions: null # The names of the SAE positions to generate dashboards for. e.g.'blocks.2.hook_resid_post'. If None, then all positions will be generated
feature_indices: null # The features for which to generate dashboards on each SAE. If none, then we'll generate dashbaords for every feature.
prompt_centric: null
seed: 0