wandb_project: gpt2-e2e
wandb_run_name: null
wandb_run_name_prefix: ''
seed: 0
tlens_model_name: gpt2-small
tlens_model_path: null
save_dir: /data/jordan_tensor/sparsify/sparsify/scripts/train_tlens_saes/out
n_samples: 300000
save_every_n_samples: 149999
eval_every_n_samples: 20000
eval_n_samples: 200
batch_size: 8
effective_batch_size: 16
lr: 0.001
lr_schedule: cosine
min_lr_factor: 0.1
warmup_samples: 20000
cooldown_samples: 0
max_grad_norm: 10.0
log_every_n_grad_steps: 20
collect_act_frequency_every_n_samples: 40000
act_frequency_n_tokens: 500000
collect_output_metrics_every_n_samples: 0
loss:
    sparsity:
      coeff: 0.8
      p_norm: 1.0
    in_to_orig: null
    out_to_orig: null
    out_to_in: null
    logits_kl:
      coeff: 1.0
train_data:
    dataset_name: apollo-research/Skylion007-openwebtext-tokenizer-gpt2
    is_tokenized: true
    tokenizer_name: gpt2
    streaming: true
    split: train
    n_ctx: 1024
    seed: 0
    column_name: input_ids
eval_data:
    dataset_name: apollo-research/Skylion007-openwebtext-tokenizer-gpt2
    is_tokenized: true
    tokenizer_name: gpt2
    streaming: true
    split: train
    n_ctx: 1024
    seed: 0
    column_name: input_ids
saes:
    type_of_sparsifier: sae
    dict_size_to_input_ratio: 60.0
    k: null
    pretrained_sae_paths: null
    retrain_saes: false
    sae_positions:
    - blocks.6.hook_resid_pre
