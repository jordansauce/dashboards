pretrained_sae_paths: "/data/jordan_tensor/dashboards/gpt2-e2e_seed-0_lpcoeff-3.0_logits-kl-1.0_lr-0.0005_ratio-60.0_blocks.6.hook_resid_pre_zgdpkafo/samples_400000.pt" # Paths of the pretrained SAEs to load. Should be a path to a .pt file, or a list of them. Can also be provided as a second argument in the command line.
sae_config_path: "/data/jordan_tensor/dashboards/gpt2-e2e_seed-0_lpcoeff-3.0_logits-kl-1.0_lr-0.0005_ratio-60.0_blocks.6.hook_resid_pre_zgdpkafo/config.yaml" # Path to the config file used to train the SAEs (if null, we'll assume it's at pretrained_sae_paths[0].parent / "config.yaml")
n_samples: 3500
batch_size: 8
minibatch_size_features: 2 # Num features in each batch of calculations. Lower to avoid OOM errors
data: # DatasetConfig for the data which will be used to generate the dashboards
  dataset_name: 'apollo-research/Skylion007-openwebtext-tokenizer-gpt2'
  is_tokenized: True
  tokenizer_name: 'gpt2'
  split: "train"
  n_ctx: 1024
save_dir: "/data/jordan_tensor/dashboards/gpt2-e2e_seed-0_lpcoeff-3.0_logits-kl-1.0_lr-0.0005_ratio-60.0_blocks.6.hook_resid_pre_zgdpkafo/dashboards_generated_with_old_sae_vis" # The directory for saving the HTML feature dashboard files
sae_positions: null # The names of the SAE positions to generate dashboards for. e.g.'blocks.2.hook_resid_post'. If None, then all positions will be generated
feature_indices: null # The features for which to generate dashboards on each SAE. If none, then we'll generate dashbaords for every feature.
prompt_centric: null # Used to generate prompt-centric (rather than feature-centric) dashboards. Feature-centric dashboards will also be generated for every feature appaearing in these
  # n_random_prompt_dashboards: 50 # The number of random prompts to generate prompt-centric dashboards for.
  # data: null # "DatasetConfig for getting random prompts. If None, then non-prompt-centric data will be used
  # prompts: # Specific prompts on which to generate prompt-centric feature dashboards. A feature-centric dashboard will be generated for every token position in each prompt.
  #   - "Sally met Mike at the show. She brought popcorn for him. They ate it together"
  #   - 'Lily asked, "Mommy, can I go on the slide?"'
  #   - "It was time for the lecture to begin."
  #   - "A man was taken to hospital after the crash"
  #   - "CAMPAIGN The campaign will focus on three core goals:"
  #   - "new_list = [n**2 for n in numbers if n%2==0]"
  # str_score: "act_quantile" # The ordering metric for which features are most important in prompt-centric dashboards. Can be one of 'act_size', 'act_quantile', or 'loss_effect'
  # num_top_features: 20 # How many of the most relevant features to show for each prompt in the prompt-centric dashboards
seed: 0